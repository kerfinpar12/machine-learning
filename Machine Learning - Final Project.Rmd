---
title: "Machine Learning - Final Project"
author: "Parker Finn"
date: "August 13, 2016"
output: html_document
---

## Executive Summary

This project uses detailed movement data collected from six individuals to model and predict the quality of a weightlifting exercises. The study collected movement data as each individual performed dumbbell curls according to five different specifications:  

* exactly according to the specification (Class A)
* throwing the elbows to the front (Class B)
* lifting the dumbbell only halfway (Class C)
* lowering the dumbbell only halfway (Class D) 
* throwing the hips to the front (Class E)

Using the train function from the Caret package, an rpart model was tested followed by a Random Forest model. The Random Forest model successfully predicts the class with very high accuracy. 

Data is from the WLE dataset from the Qualitative Activity Recognition of Weight Lifting Exercises study. (http://groupware.les.inf.puc-rio.br/har)

# Evaluation of Data

```{r, include = F, warnings = F}

setwd("~/Desktop/Coursera/Machine Learning")
#setwd("C:/Users/finnp/Downloads/Machine Learning")

library(caret)
library(ggplot2)
library(dplyr)
library(stringr)
```

```{r}
knitr::opts_chunk$set(cache=TRUE)
```

```{r}

testing <- read.csv("pml-testing.csv")
training <- read.csv("pml-training.csv")

```

The training data includes 19,622 observations and 160 fields. Fields include the subject's name and the quality of their lifting, labeled as "classe" and coded with A, B, C, D or E. 
```{r, echo=FALSE}
table(training$classe, training$user_name)
```

The first seven fields include time stamps, user names and other data not necessary for the analysis. They are removed. Many fields appear to be unnecessary derivatives of other fields.
```{r, echo=FALSE}
# First seven fields do not need to be in data. Filter.
training1 <- select(training, -(X:num_window))
```

The data is further refined by checking for zero or near zero variance predictors. 59 fields are found to be near zero varianec, i.e. they have few unique values relative to the number of samples and one value dominates. They will likely not add to the analysis and are removed. 

```{r, echo=FALSE}
#Check for near zero covariates
nsv <- nearZeroVar(training1, saveMetrics = T)
table(nsv[,"nzv"])
#59 fields are True for near zero variance

#Keep fields that are "false" for near zero variance
training2 <- training1[, nsv[,"nzv"]==FALSE] 

```

A large number of fields remain with high NA counts - 19216 NA and 406 values. Nearly 98% of data is NA for these. These variables are calculated from the other variables, presenting values such as standard deviation, max and min. These are removed.

```{r, include=FALSE}

sort(sapply(training2, function(x) sum(is.na(x))), decreasing = T)

# Remove fields with high NA
highNA <- sapply(training2, function(x) sum(is.na(x))) == 19216

```

```{r}

table(highNA)
training3 <- training2[, highNA==FALSE] 

```

# Create train and test set from training data file

The final training set for analysis includes 19,622 records and 53 variables. The data is split into a new training set (60%) with and testing set (40%) for model evaluation and testing.

```{r}

set.seed(987)
data <- createDataPartition(training3$classe, p = 0.6, list = F)

trainingNew <- training3[data,]
testingNew <- training3[-data,]

```

# RPART Model 

The first model uses the Caret package to train a model using the rpart method. This model is a poor predictor. Accuracy is only 48%. 

```{r, echo=FALSE} 

set.seed(1234)
mod1 <- train(classe ~ ., data = trainingNew, method = "rpart")
mod1
table(predict(mod1, trainingNew, type = "raw"), trainingNew$classe)
table(predict(mod1, testingNew, type = "raw"), testingNew$classe)
table(predict(mod1, trainingNew, type = "raw") == trainingNew$classe)
5678/(6098+5678)

par(mar=c(.5,.5,.5,.5))
plot(mod1$finalModel)
text(mod1$finalModel, use.n=T, all = T, cex = 0.8)

```

# Random Forest Model

The Random Forest method is used to evaluate the training set. Given the large number of variables, this method is able to optimize a much better model.

The resulting model has an accurac of 
On the testing set, the out of sample error is 

```{r, cache = TRUE, message=FALSE, warning=FALSE}

# Random Forest Model
set.seed(1234)
mod2 <- train(classe ~ ., data = trainingNew, method = "rf", 
              trControl = trainControl(method="cv", number = 5))

mod2$finalModel
mod2$results
varImp(mod2)

```

Testing the final model on the test data produces excellent results.

```{r}

# The accuracy is very hight. 98% prediction

table(predict(mod2, newdata = testingNew), testingNew$classe)

table(predict(mod2, newdata = testingNew) == testingNew$classe)
7780/(7780 + 66)

```

